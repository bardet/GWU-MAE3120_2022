{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory 08 - Time-Series Analysis\n",
    "\n",
    "## MAE 3120, Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Rubric\n",
    "\n",
    "Procedures, Results, Plots, Tables - 60%\n",
    "\n",
    "Discussion Questions - 25%\n",
    "\n",
    "Neatness - 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Background\n",
    "\n",
    "Consider a set of $n$ measurements of some variable $y$ as a function of time (or another variable $x$). Typically, $y$ is some measured output as a known function of time. In general, in such a set of measurements, there may be:\n",
    "\n",
    "1. Some random scatter (due to precision or random errors).<br><p></p>\n",
    "\n",
    "2. A trend – in spite of the scatter, $y$ may show an overall increase or, perhaps, decrease with time.\n",
    "\n",
    "We have seen in class how to address these datasets. The analysis covered in class to find trend relied on the fact that data are independent and identically distributed random variables. As briefly explained below the obtained results are not valid for analysis of time-series, which are often encountered when analyzing stock markets, turbulent velocity fields data, or global temperature trends.\n",
    "\n",
    "In time-series analysis, the scattering of the data is not random. Instead, the residual from adjacent measurements in a time-series are not independent of one another. In other words, if the $i$<sup>*th*</sup> residual is high, the $(i+1)$<sup>*th*</sup> is likely to be also high. We say that there is autocorrelation of the data. Such correlations can arise for the following reasons:\n",
    "\n",
    "1. The data of interest have a long term trend that has been overlooked in the regression analysis.<br><p></p>\n",
    "\n",
    "2. The data vary periodically (or seasonally) and this has been overlooked in the analysis.<br><p></p>\n",
    "\n",
    "3. The phenomenon under study is influenced by one or several variables that have not been included in the original analysis. These variables have long term trend or periodicity effect on the phenomenon under study.<br><p></p>\n",
    "\n",
    "4. The data are affected by random noise that is auto-correlated.\n",
    "\n",
    "Autocorrelation in data is problematic: the statistical analysis techniques we have seen rely on the errors being independent and random. Because of the dependence between the residuals, many data points are redundant and the effective numbers of degrees of freedom is significantly less than the number of measurements. Direct implications for data analysis are:\n",
    "\n",
    "1. Spurious trends may appear in your data.<br><p></p>\n",
    "\n",
    "2. Uncertainties can be grossly underestimated, especially for large datasets. Your results and analysis, though, will be unbiased.<br><p></p>\n",
    "\n",
    "3. As a result, confidence intervals will be too narrow.<br><p></p>\n",
    "\n",
    "4. Estimates of goodness of fit will be exaggerated.\n",
    "\n",
    "While it is beyond the scope of this laboratory and this class to analytically derive these results, we will demonstrate some effects by analyzing a well know dataset: The Earth Global Monthly Temperature Anomalies from 1958 to 2008. This is a particularly important dataset to analyze: it has been alleged that since there is correlation in long-term climate records no reliable trends can be observed. We will test this claim in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "1. Become more familiar with advanced concepts in correlation and regression analysis.<br><p></p>\n",
    "\n",
    "2. Improve Python skills, particularly their statistical analysis features, such as regression analysis, temporal filtering, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "### Part I - Graphical representation of the data\n",
    "\n",
    "The first step in analyzing unknown data is to generate some simple plots, in our case the temperature anomalies history. The data is in the `data` folder and is called `GlobalTemperatureAnomaly-1958-2008.csv`.\n",
    "\n",
    "1. Open the dataset in excel to have an idea of the data structures. The year in on the left column, there are 12 monthly temperature averages; i.e. 1958 represents January 1958, 1958.08 is February 1958, etc.<br><p></p>\n",
    "\n",
    "2. Let’s now generate Python code to initially display the data and then post-process them.<br><p></p>\n",
    "\n",
    "3. The data can be read in Python with the command: `Tm = pandas.read_csv('data/GlobalTemperatureAnomaly-1958-2008.csv')`. `Tm` is a an array, with the first column containing the year and month, and the second column containing the monthly average global temperature. The command `Tm.shape` gives you the dimension of `Tm`, which you might need.<br><p></p>\n",
    "\n",
    "4. For simplicity and to gain a broad picture of the data, you will display the data on a single figure in Python using subplots. You will create two plots in a 1×2 array. Display the time series of the monthly temperature anomalies versus time on the left.<br><p></p>\n",
    "\n",
    "5. Does there seems to be a clear trend? In the next section, we will smooth the data and determine the trend.<br><p></p>\n",
    "\n",
    "6. Now plot the histogram on the right hand side. <br><p></p>\n",
    "\n",
    "7. Make sure to carefully determine and justify the number of bins you selected.<br><p></p>\n",
    "\n",
    "8. What can you conclude from the shape of the histogram? Of course, you might want to compute basic statistics, such as mean, median, standard deviation, etc. to help you draw your conclusions.\n",
    "\n",
    "### Part II - Smoothing of the data and linear regression\n",
    "\n",
    "The data may have a lot of scatter. We will see one procedure, the moving average, to smooth (or filter) them and provide a better display of the trend. Be aware that there are many others. We will also define a trend for the data and study the residuals. Particularly, we are interested in finding out if the latter are correlated or not.\n",
    "\n",
    "Mathematically, a moving average of order $n$, is defined as:\n",
    "\n",
    "$$\\hat{x}_{i,\\textit{MA}(n)} = \\frac{1}{n} \\sum_{j=1}^{j=n}x_{i-j}$$\n",
    "\n",
    "It is the unweighted mean of the previous $n$ data points.\n",
    "\n",
    "1. Created a moving average of the data using the equation above.<br><p></p>\n",
    "\n",
    "2. Do you now see a clear trend in your data? Comment in your report.<br><p></p>\n",
    "\n",
    "3. Fit a straight line through your original data and display both the original data and the trend on the second subplot. Similarly to the previous plot, change the color and line thickness of the trend. Make sure to report the trend equation and your confidence level on the trend.<br><p></p>\n",
    "\n",
    "4. In the third subplot region, plot the residuals and two horizontal dotted lines for the $\\pm 2 \\sigma$.<br><p></p>\n",
    "\n",
    "  - Do you notice any clear outliers?<br><p></p>\n",
    "  \n",
    "  - Do the residuals look correlated or random?<br><p></p>\n",
    "  \n",
    "  - Do you have a valid statistics to identify outliers? In the next section, we will see two tools to easily identify this.<br><p></p>\n",
    "  \n",
    "5. In another figure, do two vertically stacked plots where you plot the residuals and their distribution, following the procedure of section 1. Do they depart significantly from normality?\n",
    "\n",
    "### Part III - Correlation in the residuals\n",
    "\n",
    "We will now study the residuals in details\n",
    "\n",
    "1. The first step is to produce a “lag plot”. For this, plot the residuals against their lags, i.e. $e_i$ vs $e_{i-1}$, as a series of dots.\n",
    "\n",
    "2. If the data are correlated, there should be significant correlation between the residuals and their lags. What is the correlation coefficient between the residuals and their lag and what is your level of confidence on the existence of a correlation?<br><p></p>\n",
    "\n",
    "3. You should have concluded that there is a correlation between the residuals. Because here one is looking at a correlation between the signal and itself, one can say there is an autocorrelation. In lights of your knowledge of regression analysis (remember linear regressions rely on the fact that the residuals are random and independent), you should now be wary of how you process the data and what you conclude from your analysis. Particularly, the uncertainty in the trend may have been underestimated, and therefore the statistical significance of your results may have been overestimated. In the next section, you will see one procedure to estimate the trend when the data are not independent.<br><p></p>\n",
    "\n",
    "4. Another tool to estimate correlation between the residuals is the autocorrelation coefficient. Mathematically it is defined as:\n",
    "\n",
    "$$\\rho_k = \\frac{\\frac{1}{N}\\sum_{l=1}^{N-k}(z_l - \\bar{z})(z_{l+k} - \\bar{z})}{\\frac{1}{N}\\sum_{l=1}^N (z_l - \\bar{z})^2}$$\n",
    "\n",
    "Here, $z_l$ is the data of interest (the residuals for your case), and $\\rho_k$ is the autocorrelation coefficient at lag $k$. Physically, this function tells you the amount of lag to which the residuals are correlated.\n",
    "\n",
    "5. Plot the autocorrelation coefficients vs the lags in the second region of the subplot routine. Add two horizontal lines indicating the ± 95% confidence interval. The intersection of $\\rho_k$ with this line indicates the lag until which your data are correlated. Report the value.<br><p></p>\n",
    "\n",
    "6. What can you conclude? You will notice that the autocorrelation coefficients are symmetric and you might want to only plot the $\\rho_k$ for positive lags to make the most efficient use of your “pixels”.\n",
    "\n",
    "### Part IV - The Cochrane-Orcutt procedure to correct for autocorrelation\n",
    "\n",
    "We will now see how we can estimate a trend for the global temperature anomalies, taking into account that the datum points are not independent. There are several approaches; we will see an “easy” one, the Cochrane-Orcutt for autocorrelation correction. In this procedure, the fitted value, $Y_i$, is a function of $Y_{i-1}$, $X_i$, $X_{i-1}$, instead of just being dependent on $X_i$ for linear regressions: \n",
    "\n",
    "$$Y_i = rY_{i-1} + a(1-r) + b(x_i - rx_{i-1}) + \\epsilon_i$$\n",
    "\n",
    "Where $r$ is the autocorrelation coefficient at lag 1 of the residuals; $a$ and $b$ are two constant parameters that need to be determined. Here are the steps for this procedure.\n",
    "\n",
    "1. Do a linear regression of $Y$ vs $X$. Test the residuals for autocorrelation, if there is none, then, stop here. Otherwise, follow the steps below. Of course, for the global temperature anomalies there is correlation in the residuals.<br><p></p>\n",
    "\n",
    "2. Calculate the correlation coefficient, $r$, between the residuals, $e_i$ and their lags $e_{i-1}$. You should have calculated it already. Transform the $X$ and $Y$ into:\n",
    "\n",
    "$$X_i^{'} = X_i - rX_{i-1}$$\n",
    "\n",
    "$$Y_i^{'} = Y_i - rY_{i-1}$$\n",
    "\n",
    "3. Perform a linear regression of $Y_i'$ vs $X_i'$, i.e. find the $a'$ & $b'$, such that:\n",
    "\n",
    "$$Y_i^{'} = a' + b' X_i^{'} + e_i^{'}$$\n",
    "\n",
    "4. Plot the residuals from this second regression against the lag 1 autocorrelation, i.e. $e_i'$ vs $e_{i-1}'$ and check whether the correlation between them has been eliminated. If so, you have finished:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$b = b'$ is the best estimate for the slope of $Y$ vs $X$, and\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$a = \\frac{a'}{1 - r}$ for the intercept.\n",
    "\n",
    "5. If there is still correlation between the residuals, update your value for $r$ by calculating the lag 1 autocorrelation coefficient of the following residuals:\n",
    "\n",
    "$$e_i^{''} = Y_i - \\frac{a'}{1 - r} - b'X_i$$\n",
    "\n",
    "6. Restart the procedure at step 2. The Cochrane-Orcutt should converge (give independent residuals) after only one or two iterations.<br><p></p>\n",
    "\n",
    "7. In a figure with two vertically stacked subplots. On the first one, plot the raw data with the first linear regression you did. On the second, plot the raw data and the improved linear fit. Report the values of the slopes for both.<br><p></p>\n",
    "\n",
    "8. In your report discuss the following points:<br><p></p>\n",
    "\n",
    "  - What is the slopes ratio between the “standard” slope and the new “improved” one?<br><p></p>\n",
    "\n",
    "  - Did the autocorrelation in the datum points significantly affect your original prediction?<br><p></p>\n",
    "\n",
    " - What is your confidence on your new trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Questions\n",
    "\n",
    "1. How is the global temperature anomaly calculated?<br><p></p>\n",
    "\n",
    "2. What does it mean and why is it employed instead of the global mean temperature to quantify global warming?<br><p></p>\n",
    "\n",
    "3. Why is it important to check that the residuals are independent and random when performing a linear regression?<br><p></p>\n",
    "\n",
    "4. In this particular case, is it possible to still estimate a trend with confidence?<br><p></p>\n",
    "\n",
    "5. What is your best estimate of the global temperature by the end of the 22nd century?<br><p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4.htm\n",
    "\n",
    "http://www.itl.nist.gov/div898/handbook/eda/eda.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
